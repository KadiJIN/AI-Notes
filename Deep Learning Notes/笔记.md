# Deep Learning
## Introduction
早期的人工智能解决了人类在智力上难以解决的问题，但这些问题对于计算机来说很简单。真正的难题是解决人们容易执行却很难描述的任务，比如识别文字和图片。
我们人类直观地解决这些任务，非常自然，但对于机器来说不是。本书围绕这一系列的直观问题展开，目的是允许计算机按照概念的层次结构从经验中学习并了解世界。 
  
To summarize, deep learning, the subject of this book, is an approach to AI.   
Speciﬁcally, it is a type of machine learning, a technique that enables computer systems to improve with experience and data. We contend that machine learning is the only viable approach to building AI systems that can operate in complicated real-world environments. Deep learning is a particular kind of machine learning that achieves great power and ﬂexibility by representing the world as a nested hierarchy of concepts, with each concept deﬁned in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones.  
  
In summary, deep learning is an approach to machine learning that has drawn heavily on our knowledge of the human brain, statistics and applied math as it
developed over the past several decades. In recent years, deep learning has seen tremendous growth in its popularity and usefulness, largely as the result of more powerful computers, larger datasets and techniques to train deeper networks. The years ahead are full of challenges and opportunities to improve deep learning even further and to bring it to new frontiers.
## Applied Math and Machine Learning Basics
### Linear Algebra
线性代数的一些知识  
#### Scalars, Vectors, Matrices and Tensors
Tensors : In some cases we will need an array with more than two axes. In the general case, an array of numbers arranged on a regular grid with a
variable number of axes is known as a tensor. We denote a tensor named “A”with this typeface: A. We identify the element of A at coordinates (i, j, k) by writing A i,j,k.  
One important operation on matrices is the **transpose**. 转置: 把A的横行写为AT的纵列,把A的纵列写为AT的横行  
#### Multiplying Matrices and Vectors
矩阵乘法： ![乘法](https://upload-images.jianshu.io/upload_images/13717038-1043e03126f1e708.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
#### Identity and Inverse Matrices
#### Linear Dependence and Span
The **span** of a set of vectors is the set of all points obtainable by linear combination of the original vectors.
#### Norms
#### Special Kinds of Matrices and Vectors
#### Eigendecomposition
#### Singular Value Decomposition
#### The Moore-Penrose Pseudoinverse
#### The Trace Operator
#### The Determinant
#### PCA
### Probability and Information Theory
#### Useful Properties of Common Functions
logistic sigmoid  
logistic sigmoid函数通常用来产生Bernoulli分布中的参数ø，因为它的范围是(0,1)，处在ø的有效取值范围内。logisitic sigmoid函数在变量取绝对值非常大的正值或负值时会出现饱和(saturate)现象，意味着函数会变得很平，并且对输入的微小改变会变得不敏感。
logistic sigmoid函数在深度学习中经常用作激活函数。有时为了加快计算速度，也使用称为fast sigmoid 函数，即：σ(x)=x/(1+|x|)  

ReLu 
线性整流函数（Rectified Linear Unit, ReLU），又称修正线性单元，是一种人工神经网络中常用的激活函数，通常指代以斜坡函数及其变种为代表的非线性函数。
优势：更加有效率的梯度下降以及反向传播：避免了梯度爆炸和梯度消失问题  

softplus function  
ReLu 函数的平滑版

#### Structured Probabilistic Models
##### 有向图模型
##### 无向图模型
### Numerical Computation
